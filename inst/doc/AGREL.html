<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />

<meta name="viewport" content="width=device-width, initial-scale=1">

<meta name="author" content="De Cock Bavo" />

<meta name="date" content="2017-07-07" />

<title>Agreement and reliability analysis using AGREL</title>



<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>



<link href="data:text/css;charset=utf-8,body%20%7B%0Abackground%2Dcolor%3A%20%23fff%3B%0Amargin%3A%201em%20auto%3B%0Amax%2Dwidth%3A%20700px%3B%0Aoverflow%3A%20visible%3B%0Apadding%2Dleft%3A%202em%3B%0Apadding%2Dright%3A%202em%3B%0Afont%2Dfamily%3A%20%22Open%20Sans%22%2C%20%22Helvetica%20Neue%22%2C%20Helvetica%2C%20Arial%2C%20sans%2Dserif%3B%0Afont%2Dsize%3A%2014px%3B%0Aline%2Dheight%3A%201%2E35%3B%0A%7D%0A%23header%20%7B%0Atext%2Dalign%3A%20center%3B%0A%7D%0A%23TOC%20%7B%0Aclear%3A%20both%3B%0Amargin%3A%200%200%2010px%2010px%3B%0Apadding%3A%204px%3B%0Awidth%3A%20400px%3B%0Aborder%3A%201px%20solid%20%23CCCCCC%3B%0Aborder%2Dradius%3A%205px%3B%0Abackground%2Dcolor%3A%20%23f6f6f6%3B%0Afont%2Dsize%3A%2013px%3B%0Aline%2Dheight%3A%201%2E3%3B%0A%7D%0A%23TOC%20%2Etoctitle%20%7B%0Afont%2Dweight%3A%20bold%3B%0Afont%2Dsize%3A%2015px%3B%0Amargin%2Dleft%3A%205px%3B%0A%7D%0A%23TOC%20ul%20%7B%0Apadding%2Dleft%3A%2040px%3B%0Amargin%2Dleft%3A%20%2D1%2E5em%3B%0Amargin%2Dtop%3A%205px%3B%0Amargin%2Dbottom%3A%205px%3B%0A%7D%0A%23TOC%20ul%20ul%20%7B%0Amargin%2Dleft%3A%20%2D2em%3B%0A%7D%0A%23TOC%20li%20%7B%0Aline%2Dheight%3A%2016px%3B%0A%7D%0Atable%20%7B%0Amargin%3A%201em%20auto%3B%0Aborder%2Dwidth%3A%201px%3B%0Aborder%2Dcolor%3A%20%23DDDDDD%3B%0Aborder%2Dstyle%3A%20outset%3B%0Aborder%2Dcollapse%3A%20collapse%3B%0A%7D%0Atable%20th%20%7B%0Aborder%2Dwidth%3A%202px%3B%0Apadding%3A%205px%3B%0Aborder%2Dstyle%3A%20inset%3B%0A%7D%0Atable%20td%20%7B%0Aborder%2Dwidth%3A%201px%3B%0Aborder%2Dstyle%3A%20inset%3B%0Aline%2Dheight%3A%2018px%3B%0Apadding%3A%205px%205px%3B%0A%7D%0Atable%2C%20table%20th%2C%20table%20td%20%7B%0Aborder%2Dleft%2Dstyle%3A%20none%3B%0Aborder%2Dright%2Dstyle%3A%20none%3B%0A%7D%0Atable%20thead%2C%20table%20tr%2Eeven%20%7B%0Abackground%2Dcolor%3A%20%23f7f7f7%3B%0A%7D%0Ap%20%7B%0Amargin%3A%200%2E5em%200%3B%0A%7D%0Ablockquote%20%7B%0Abackground%2Dcolor%3A%20%23f6f6f6%3B%0Apadding%3A%200%2E25em%200%2E75em%3B%0A%7D%0Ahr%20%7B%0Aborder%2Dstyle%3A%20solid%3B%0Aborder%3A%20none%3B%0Aborder%2Dtop%3A%201px%20solid%20%23777%3B%0Amargin%3A%2028px%200%3B%0A%7D%0Adl%20%7B%0Amargin%2Dleft%3A%200%3B%0A%7D%0Adl%20dd%20%7B%0Amargin%2Dbottom%3A%2013px%3B%0Amargin%2Dleft%3A%2013px%3B%0A%7D%0Adl%20dt%20%7B%0Afont%2Dweight%3A%20bold%3B%0A%7D%0Aul%20%7B%0Amargin%2Dtop%3A%200%3B%0A%7D%0Aul%20li%20%7B%0Alist%2Dstyle%3A%20circle%20outside%3B%0A%7D%0Aul%20ul%20%7B%0Amargin%2Dbottom%3A%200%3B%0A%7D%0Apre%2C%20code%20%7B%0Abackground%2Dcolor%3A%20%23f7f7f7%3B%0Aborder%2Dradius%3A%203px%3B%0Acolor%3A%20%23333%3B%0Awhite%2Dspace%3A%20pre%2Dwrap%3B%20%0A%7D%0Apre%20%7B%0Aborder%2Dradius%3A%203px%3B%0Amargin%3A%205px%200px%2010px%200px%3B%0Apadding%3A%2010px%3B%0A%7D%0Apre%3Anot%28%5Bclass%5D%29%20%7B%0Abackground%2Dcolor%3A%20%23f7f7f7%3B%0A%7D%0Acode%20%7B%0Afont%2Dfamily%3A%20Consolas%2C%20Monaco%2C%20%27Courier%20New%27%2C%20monospace%3B%0Afont%2Dsize%3A%2085%25%3B%0A%7D%0Ap%20%3E%20code%2C%20li%20%3E%20code%20%7B%0Apadding%3A%202px%200px%3B%0A%7D%0Adiv%2Efigure%20%7B%0Atext%2Dalign%3A%20center%3B%0A%7D%0Aimg%20%7B%0Abackground%2Dcolor%3A%20%23FFFFFF%3B%0Apadding%3A%202px%3B%0Aborder%3A%201px%20solid%20%23DDDDDD%3B%0Aborder%2Dradius%3A%203px%3B%0Aborder%3A%201px%20solid%20%23CCCCCC%3B%0Amargin%3A%200%205px%3B%0A%7D%0Ah1%20%7B%0Amargin%2Dtop%3A%200%3B%0Afont%2Dsize%3A%2035px%3B%0Aline%2Dheight%3A%2040px%3B%0A%7D%0Ah2%20%7B%0Aborder%2Dbottom%3A%204px%20solid%20%23f7f7f7%3B%0Apadding%2Dtop%3A%2010px%3B%0Apadding%2Dbottom%3A%202px%3B%0Afont%2Dsize%3A%20145%25%3B%0A%7D%0Ah3%20%7B%0Aborder%2Dbottom%3A%202px%20solid%20%23f7f7f7%3B%0Apadding%2Dtop%3A%2010px%3B%0Afont%2Dsize%3A%20120%25%3B%0A%7D%0Ah4%20%7B%0Aborder%2Dbottom%3A%201px%20solid%20%23f7f7f7%3B%0Amargin%2Dleft%3A%208px%3B%0Afont%2Dsize%3A%20105%25%3B%0A%7D%0Ah5%2C%20h6%20%7B%0Aborder%2Dbottom%3A%201px%20solid%20%23ccc%3B%0Afont%2Dsize%3A%20105%25%3B%0A%7D%0Aa%20%7B%0Acolor%3A%20%230033dd%3B%0Atext%2Ddecoration%3A%20none%3B%0A%7D%0Aa%3Ahover%20%7B%0Acolor%3A%20%236666ff%3B%20%7D%0Aa%3Avisited%20%7B%0Acolor%3A%20%23800080%3B%20%7D%0Aa%3Avisited%3Ahover%20%7B%0Acolor%3A%20%23BB00BB%3B%20%7D%0Aa%5Bhref%5E%3D%22http%3A%22%5D%20%7B%0Atext%2Ddecoration%3A%20underline%3B%20%7D%0Aa%5Bhref%5E%3D%22https%3A%22%5D%20%7B%0Atext%2Ddecoration%3A%20underline%3B%20%7D%0A%0Acode%20%3E%20span%2Ekw%20%7B%20color%3A%20%23555%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%0Acode%20%3E%20span%2Edt%20%7B%20color%3A%20%23902000%3B%20%7D%20%0Acode%20%3E%20span%2Edv%20%7B%20color%3A%20%2340a070%3B%20%7D%20%0Acode%20%3E%20span%2Ebn%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Efl%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Ech%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Est%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Eco%20%7B%20color%3A%20%23888888%3B%20font%2Dstyle%3A%20italic%3B%20%7D%20%0Acode%20%3E%20span%2Eot%20%7B%20color%3A%20%23007020%3B%20%7D%20%0Acode%20%3E%20span%2Eal%20%7B%20color%3A%20%23ff0000%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%0Acode%20%3E%20span%2Efu%20%7B%20color%3A%20%23900%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%20code%20%3E%20span%2Eer%20%7B%20color%3A%20%23a61717%3B%20background%2Dcolor%3A%20%23e3d2d2%3B%20%7D%20%0A" rel="stylesheet" type="text/css" />

</head>

<body>




<h1 class="title toc-ignore">Agreement and reliability analysis using AGREL</h1>
<h4 class="author"><em>De Cock Bavo</em></h4>
<h4 class="date"><em>2017-07-07</em></h4>


<div id="TOC">
<ul>
<li><a href="#introduction">1. Introduction</a></li>
<li><a href="#agreement-indices">2. Agreement indices</a><ul>
<li><a href="#two-raters-dichotomous-variable">2.1 Two raters, dichotomous variable</a></li>
<li><a href="#more-than-two-raters-dichotomous-variable">2.2 More than two raters, dichotomous variable</a></li>
<li><a href="#more-than-2-raters-multinomial-variable">2.3 More than 2 raters, multinomial variable</a></li>
</ul></li>
<li><a href="#reliability">3. Reliability</a><ul>
<li><a href="#cohens-kappa">3.1 Cohen’s Kappa</a></li>
<li><a href="#weighted-kappa">3.2 Weighted Kappa</a></li>
<li><a href="#fleiss-kappa">3.3 Fleiss’ Kappa</a></li>
<li><a href="#matrix-of-kappa-type-coefficients">3.4 Matrix of Kappa-type coefficients</a></li>
<li><a href="#bland-altman-plot-for-multiple-observers">3.5 Bland-Altman plot for multiple observers</a></li>
</ul></li>
<li><a href="#data-transformation-of-the-dataframe">4. Data transformation of the dataframe</a></li>
<li><a href="#references">References</a></li>
</ul>
</div>

<div id="introduction" class="section level1">
<h1>1. Introduction</h1>
<p>In this document, the various functions of the AGREL package will be explained and illustrated. The AGREL package contains functions for calculating agreement and reliability. With regard to agreement, the following statistics can be calculated:</p>
<ul>
<li>Overall proportion of agreement</li>
<li>Specific agreement</li>
</ul>
<p>For reliability:</p>
<ul>
<li>Cohen’s kappa</li>
<li>Weighted kappa</li>
<li>Fleiss’ kappa</li>
<li>Matrix of kappa-type coefficients</li>
<li>Bland-Altman plot for multiple observers</li>
</ul>
<p>More functions to calculate the agreement and reliability will be added in the future.</p>
</div>
<div id="agreement-indices" class="section level1">
<h1>2. Agreement indices</h1>
<p>Agreement statistics are an absolute measure of agreement. They indicate how similar the observed ratings are and hence, are to be used when one wants the quantify the amount of agreement. For example, if two doctors diagnosed <span class="math inline">\(N\)</span> patients and we want to know the proportion of similar diagnoses.</p>
<p>To illustrate the calculation of the overall proportion of agreement and specific agreement, we will use the example of de Vet et al. (2017). In this example, 4 surgeons rated the photographs of breasts of 50 women after breast reconstruction. The original five-point ordinal scale was dichotomized into satisfied and dissatisfied.</p>
<div id="two-raters-dichotomous-variable" class="section level2">
<h2>2.1 Two raters, dichotomous variable</h2>
<p>For the first example, we only take the data from the first two surgeons and refer to the surgeons as rater A and rater B. The results are depicted in the following two-by-two table:</p>
<table class="gmisc_table" style="border-collapse: collapse; margin-top: 1em; margin-bottom: 1em;" id="table_1">
<thead>
<tr>
<td colspan="5" style="text-align: left;">
Table 1: Two raters, dichotomous variable
</td>
</tr>
<tr>
<th style="border-top: 2px solid grey;">
</th>
<th colspan="2" style="font-weight: 900; border-bottom: 1px solid grey; border-top: 2px solid grey; text-align: center;">
Rater B
</th>
<th style="border-top: 2px solid grey;; border-bottom: hidden;">
 
</th>
<th colspan="1" style="font-weight: 900; border-top: 2px solid grey; text-align: center;">
</th>
</tr>
<tr>
<th style="font-weight: 900; border-bottom: 1px solid grey; text-align: center;">
Rater A
</th>
<th style="border-bottom: 1px solid grey; text-align: center;">
Satisfied
</th>
<th style="border-bottom: 1px solid grey; text-align: center;">
Dissatisfied
</th>
<th style="border-bottom: 1px solid grey;" colspan="1">
 
</th>
<th style="border-bottom: 1px solid grey; text-align: center;">
Sum
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">
<b>Satisfied</b>
</td>
<td style="text-align: center;">
19
</td>
<td style="text-align: center;">
5
</td>
<td style colspan="1">
 
</td>
<td style="text-align: center;">
24
</td>
</tr>
<tr>
<td style="text-align: left;">
<b>Dissatisfied</b>
</td>
<td style="text-align: center;">
9
</td>
<td style="text-align: center;">
17
</td>
<td style colspan="1">
 
</td>
<td style="text-align: center;">
26
</td>
</tr>
<tr>
<td style="border-bottom: 2px solid grey; text-align: left;">
<b>Sum</b>
</td>
<td style="border-bottom: 2px solid grey; text-align: center;">
28
</td>
<td style="border-bottom: 2px solid grey; text-align: center;">
22
</td>
<td style="border-bottom: 2px solid grey;" colspan="1">
 
</td>
<td style="border-bottom: 2px solid grey; text-align: center;">
50
</td>
</tr>
</tbody>
</table>
<p>This table can be constructed as follows</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(AGREL)
<span class="kw">data</span>(<span class="st">&quot;Agreement_deVetArticle&quot;</span>)
tmp =<span class="st"> </span>Agreement_deVetArticle[,<span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">2</span>)]
<span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="dv">2</span>) tmp[,i] =<span class="st"> </span><span class="kw">factor</span>(tmp[,i], <span class="dt">level=</span><span class="kw">c</span>(<span class="st">&quot;Satisfied&quot;</span>, <span class="st">&quot;Dissatisfied&quot;</span>), <span class="dt">ordered=</span>T)
TableExample =<span class="st"> </span><span class="kw">table</span>(tmp, <span class="dt">dnn =</span> <span class="kw">c</span>(<span class="st">&quot;Rater A&quot;</span>, <span class="st">&quot;Rater B&quot;</span>))
TableExample =<span class="st"> </span><span class="kw">addmargins</span>(TableExample)
TableExample</code></pre></div>
<pre><code>##               Rater B
## Rater A        Satisfied Dissatisfied Sum
##   Satisfied           19            5  24
##   Dissatisfied         9           17  26
##   Sum                 28           22  50</code></pre>
<p>To calculate the specific agreement (<span class="math inline">\(P_s\)</span>) and overall proportion of agreement (<span class="math inline">\(P_o\)</span>), we can use the <span class="math inline">\(\verb|DiagnosticAgreement.deVet()|\)</span> function from the package. The methodology to calculate <span class="math inline">\(P_s\)</span> and <span class="math inline">\(P_o\)</span> is described in de Vet et al. (2013). A dataframe or matrix serves as the input, where the columns contain the ratings of each of the raters. Hence, an <span class="math inline">\(N \times P\)</span> dataframe or matrix is given as input with <span class="math inline">\(N\)</span> the number of subjects and <span class="math inline">\(P\)</span> the number of raters.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">head</span>(tmp)</code></pre></div>
<pre><code>##       Surgeon1     Surgeon2
## 1    Satisfied    Satisfied
## 2 Dissatisfied Dissatisfied
## 3    Satisfied Dissatisfied
## 4 Dissatisfied Dissatisfied
## 5 Dissatisfied    Satisfied
## 6    Satisfied Dissatisfied</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">Results1 =<span class="st"> </span><span class="kw">DiagnosticAgreement.deVet</span>(tmp)
Results1</code></pre></div>
<pre><code>## 
## #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#
## #          Agreement           #
## #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#
## 
## - Number of raters = 2 
## 
## - Sample size = 50 
## 
## 
## - Summed table:
## 
##              Satisfied Dissatisfied
## Satisfied           19            7
## Dissatisfied         7           17
## 
## 
## - Observed Agreement:
## 
##           LowerCI ObservedAgreement           UpperCI 
##         0.6055461         0.7200000         0.8544539 
## 
## 
## - Specific Agreement:
## 
##                LowerCI SpecificAgreement   UpperCI
## Satisfied    0.5795041         0.7307692 0.9204959
## Dissatisfied 0.5473203         0.7083333 0.9110131</code></pre>
<p>Note that the summed table is not the same as table 1. This is important as it depicts the table as described in de Vet et al. (2017) and this will be explained more in detail in section 2.2.</p>
<p>We can indicate whether confidence intervals (CI) for <span class="math inline">\(P_s\)</span> and <span class="math inline">\(P_o\)</span> have to be calculated using the logical argument <span class="math inline">\(\verb|CI|\)</span> and the confidence level can be changed in the argument <span class="math inline">\(\verb|ConfLevel|\)</span>. Different methods can be used to calculate the CI, namely the continuity correction, Fleiss correction or by use of the bootstrap methodology. The default method for calculating CIs is the continuity correction and this can be changed by specifying the method in the argument <span class="math inline">\(\verb|correction|\)</span>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">DiagnosticAgreement.deVet</span>(tmp, <span class="dt">correction =</span> <span class="st">&quot;Fleiss&quot;</span>)</code></pre></div>
<pre><code>## 
## #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#
## #          Agreement           #
## #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#
## 
## - Number of raters = 2 
## 
## - Sample size = 50 
## 
## 
## - Summed table:
## 
##              Satisfied Dissatisfied
## Satisfied           19            7
## Dissatisfied         7           17
## 
## 
## - Observed Agreement:
## 
##           LowerCI ObservedAgreement           UpperCI 
##         0.5728902         0.7200000         0.8171438 
## 
## 
## - Specific Agreement:
## 
##                LowerCI SpecificAgreement   UpperCI
## Satisfied    0.5194943         0.7307692 0.8491204
## Dissatisfied 0.4875243         0.7083333 0.8357346</code></pre>
<p>If one wants to use the bootstrap methodology to calculate the CIs, the number of bootstrap samples to be taken can be specified and parallel computing can be used to get the results faster. The latter is recommended only in cases of a large dataframe.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">DiagnosticAgreement.deVet</span>(tmp, <span class="dt">correction =</span> <span class="st">&quot;bootstrap&quot;</span>, <span class="dt">NrBoot =</span> <span class="dv">500</span>)</code></pre></div>
<pre><code>## 
## #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#
## #          Agreement           #
## #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#
## 
## - Number of raters = 2 
## 
## - Sample size = 50 
## 
## 
## - Summed table:
## 
##              Satisfied Dissatisfied
## Satisfied           19            7
## Dissatisfied         7           17
## 
## 
## - Observed Agreement:
## 
##           LowerCI ObservedAgreement           UpperCI 
##              0.60              0.72              0.84 
## 
## 
## - Specific Agreement:
## 
##                LowerCI SpecificAgreement   UpperCI
## Satisfied    0.5675824         0.7307692 0.8468383
## Dissatisfied 0.5365854         0.7083333 0.8468383</code></pre>
</div>
<div id="more-than-two-raters-dichotomous-variable" class="section level2">
<h2>2.2 More than two raters, dichotomous variable</h2>
<p>In case of more than two raters, the same function can be used and the method to calculate <span class="math inline">\(P_s\)</span> and <span class="math inline">\(P_o\)</span> is described in de Vet et al. (2017).</p>
<p>Asssume that we now have the results of a third rater, rater C. Since we now have 3 raters, 3 two-by-two tables can be constructed: <span class="math display">\[
\frac{m(m - 1)}{2}\\
= \frac{3 \times 2}{2} = 3
\]</span> where <span class="math inline">\(m\)</span> is the number of raters. We already have the table for rater A versus rater B. The other two tables are those for rater A versus rater C and rater B versus rater C.</p>
<table class="gmisc_table" style="border-collapse: collapse; margin-top: 1em; margin-bottom: 1em;" id="table_2">
<thead>
<tr>
<td colspan="5" style="text-align: left;">
Table 2: &gt; 2 raters, dichotomous variable
</td>
</tr>
<tr>
<th style="border-top: 2px solid grey;">
</th>
<th colspan="2" style="font-weight: 900; border-bottom: 1px solid grey; border-top: 2px solid grey; text-align: center;">
Rater C
</th>
<th style="border-top: 2px solid grey;; border-bottom: hidden;">
 
</th>
<th colspan="1" style="font-weight: 900; border-top: 2px solid grey; text-align: center;">
</th>
</tr>
<tr>
<th style="font-weight: 900; border-bottom: 1px solid grey; text-align: center;">
Rater A
</th>
<th style="border-bottom: 1px solid grey; text-align: center;">
Satisfied
</th>
<th style="border-bottom: 1px solid grey; text-align: center;">
Dissatisfied
</th>
<th style="border-bottom: 1px solid grey;" colspan="1">
 
</th>
<th style="border-bottom: 1px solid grey; text-align: center;">
Sum
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">
<b>Satisfied</b>
</td>
<td style="text-align: center;">
20
</td>
<td style="text-align: center;">
4
</td>
<td style colspan="1">
 
</td>
<td style="text-align: center;">
24
</td>
</tr>
<tr>
<td style="text-align: left;">
<b>Dissatisfied</b>
</td>
<td style="text-align: center;">
8
</td>
<td style="text-align: center;">
18
</td>
<td style colspan="1">
 
</td>
<td style="text-align: center;">
26
</td>
</tr>
<tr>
<td style="border-bottom: 2px solid grey; text-align: left;">
<b>Sum</b>
</td>
<td style="border-bottom: 2px solid grey; text-align: center;">
28
</td>
<td style="border-bottom: 2px solid grey; text-align: center;">
22
</td>
<td style="border-bottom: 2px solid grey;" colspan="1">
 
</td>
<td style="border-bottom: 2px solid grey; text-align: center;">
50
</td>
</tr>
</tbody>
</table>
<table class="gmisc_table" style="border-collapse: collapse; margin-top: 1em; margin-bottom: 1em;" id="table_3">
<thead>
<tr>
<td colspan="5" style="text-align: left;">
Table 3: &gt; 2 raters, dichotomous variable
</td>
</tr>
<tr>
<th style="border-top: 2px solid grey;">
</th>
<th colspan="2" style="font-weight: 900; border-bottom: 1px solid grey; border-top: 2px solid grey; text-align: center;">
Rater C
</th>
<th style="border-top: 2px solid grey;; border-bottom: hidden;">
 
</th>
<th colspan="1" style="font-weight: 900; border-top: 2px solid grey; text-align: center;">
</th>
</tr>
<tr>
<th style="font-weight: 900; border-bottom: 1px solid grey; text-align: center;">
Rater B
</th>
<th style="border-bottom: 1px solid grey; text-align: center;">
Satisfied
</th>
<th style="border-bottom: 1px solid grey; text-align: center;">
Dissatisfied
</th>
<th style="border-bottom: 1px solid grey;" colspan="1">
 
</th>
<th style="border-bottom: 1px solid grey; text-align: center;">
Sum
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">
<b>Satisfied</b>
</td>
<td style="text-align: center;">
23
</td>
<td style="text-align: center;">
5
</td>
<td style colspan="1">
 
</td>
<td style="text-align: center;">
28
</td>
</tr>
<tr>
<td style="text-align: left;">
<b>Dissatisfied</b>
</td>
<td style="text-align: center;">
5
</td>
<td style="text-align: center;">
17
</td>
<td style colspan="1">
 
</td>
<td style="text-align: center;">
22
</td>
</tr>
<tr>
<td style="border-bottom: 2px solid grey; text-align: left;">
<b>Sum</b>
</td>
<td style="border-bottom: 2px solid grey; text-align: center;">
28
</td>
<td style="border-bottom: 2px solid grey; text-align: center;">
22
</td>
<td style="border-bottom: 2px solid grey;" colspan="1">
 
</td>
<td style="border-bottom: 2px solid grey; text-align: center;">
50
</td>
</tr>
</tbody>
</table>
<p>The above tables can be reproduced using</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># 3 raters</span>

<span class="co"># A vs C</span>
tmp =<span class="st"> </span>Agreement_deVetArticle[,<span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">4</span>)]
<span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="dv">2</span>) tmp[,i] =<span class="st"> </span><span class="kw">factor</span>(tmp[,i], <span class="dt">level=</span><span class="kw">c</span>(<span class="st">&quot;Satisfied&quot;</span>, <span class="st">&quot;Dissatisfied&quot;</span>), <span class="dt">ordered=</span>T)
TableExample2 =<span class="st"> </span><span class="kw">table</span>(tmp)
TableExample2 =<span class="st"> </span><span class="kw">addmargins</span>(TableExample2)
TableExample2</code></pre></div>
<pre><code>##               Surgeon4
## Surgeon1       Satisfied Dissatisfied Sum
##   Satisfied           20            4  24
##   Dissatisfied         8           18  26
##   Sum                 28           22  50</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># B vs C</span>
tmp =<span class="st"> </span>Agreement_deVetArticle[,<span class="kw">c</span>(<span class="dv">2</span>,<span class="dv">4</span>)]
<span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="dv">2</span>) tmp[,i] =<span class="st"> </span><span class="kw">factor</span>(tmp[,i], <span class="dt">level=</span><span class="kw">c</span>(<span class="st">&quot;Satisfied&quot;</span>, <span class="st">&quot;Dissatisfied&quot;</span>), <span class="dt">ordered=</span>T)
TableExample3 =<span class="st"> </span><span class="kw">table</span>(tmp)
TableExample3 =<span class="st"> </span><span class="kw">addmargins</span>(TableExample3)
TableExample3</code></pre></div>
<pre><code>##               Surgeon4
## Surgeon2       Satisfied Dissatisfied Sum
##   Satisfied           23            5  28
##   Dissatisfied         5           17  22
##   Sum                 28           22  50</code></pre>
<p>Using the results from these 3 raters, we can calculate the <span class="math inline">\(P_s\)</span> and <span class="math inline">\(P_o\)</span> using</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">DiagnosticAgreement.deVet</span>(Agreement_deVetArticle[,<span class="kw">c</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">2</span>,<span class="dv">4</span>)])</code></pre></div>
<pre><code>## 
## #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#
## #          Agreement           #
## #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#
## 
## - Number of raters = 3 
## 
## - Sample size = 50 
## 
## 
## - Summed table:
## 
##              Dissatisfied Satisfied
## Dissatisfied           52        18
## Satisfied              18        62
## 
## 
## - Observed Agreement:
## 
##           LowerCI ObservedAgreement           UpperCI 
##         0.6675264         0.7600000         0.8666157 
## 
## 
## - Specific Agreement:
## 
##                LowerCI SpecificAgreement   UpperCI
## Dissatisfied 0.6088873         0.7428571 0.9071316
## Satisfied    0.6549834         0.7750000 0.9215331</code></pre>
</div>
<div id="more-than-2-raters-multinomial-variable" class="section level2">
<h2>2.3 More than 2 raters, multinomial variable</h2>
<p>When the variable is multinomial, the <span class="math inline">\(P_s\)</span> and <span class="math inline">\(P_o\)</span> can be calculated using the methodology of Uebersax (1982). Note that this function can also be used in case of a dichotomous variable and/or when there are only 2 raters.</p>
<p>For this example, we use the data of Fleiss (1971) where 6 psychiatrist diagnosed 30 patients. Possible diagnoses were depression, personality disorder, schizophrenia, neurosis and other. To calculate <span class="math inline">\(P_s\)</span> and <span class="math inline">\(P_o\)</span>, we use the function <span class="math inline">\(\verb|AgreemGeneralizedVector()|\)</span>. Note that this as a temporary function which gives a minimum of output. A more detailed and advanced function will be made public in the future after publication on a new methodology to assess specific agreement.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">data</span>(<span class="st">&quot;PsychMorbid&quot;</span>)
<span class="kw">AgreemGeneralizedVector</span>(PsychMorbid)</code></pre></div>
<pre><code>## 
## #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#
## # Agreement for multinomial variables #
## #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#
## 
## - Number of raters = 6 
## 
## - Sample size = 30 
## 
## - Overall agreement = 0.556
## 
## - Specific agreement:
## 
##                      Ps
## neurosis      0.6327273
## PD            0.3538462
## other         0.6697674
## depression    0.3538462
## schizophrenia 0.6000000</code></pre>
</div>
</div>
<div id="reliability" class="section level1">
<h1>3. Reliability</h1>
<p>In contrast to agreement, reliability is a relative measure. Reliability indicates how reliable a measurement method is to make a distinction between subjects. Hence, if one wants to know to what extent a measurement can differentiate between subjects, reliability statistics have to be used.</p>
<div id="cohens-kappa" class="section level2">
<h2>3.1 Cohen’s Kappa</h2>
<p>In case of two raters, one can use Cohen’s Kappa (Cohen, 1960). We can, for example, take the ratings of the first 2 raters of the <span class="math inline">\(\verb|PsychMorbid|\)</span> dataset.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">Df =<span class="st"> </span>PsychMorbid[,<span class="dv">1</span><span class="op">:</span><span class="dv">2</span>]
<span class="kw">CohenK</span>(Df)</code></pre></div>
<pre><code>## 
## #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#
## #       Cohen's Kappa          #
## #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#
## 
## - Number of raters = 2 
## 
## - Sample size = 30 
## 
## - Cohen's Kappa = 0.651 
## 
## - Overall proportion of agreement: 0.7333333 
## 
## - Proportion chance agreement: 0.2355556 
## 
## - Used weights =  unweighted</code></pre>
<p>The most important information is printed in the R console. More detailed information can be obtained when the output is stored in an object and information regarding the output can be found in the help file of <span class="math inline">\(\verb|CohenK()|\)</span>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">?CohenK
ResultsCohenK =<span class="st"> </span><span class="kw">CohenK</span>(Df)
<span class="kw">str</span>(ResultsCohenK)</code></pre></div>
<pre><code>## List of 13
##  $ method   : chr &quot;Cohen's Kappa for 2 Raters (Weights: unweighted)&quot;
##  $ subjects : int 30
##  $ nraters  : int 2
##  $ irr.name : chr &quot;Kappa&quot;
##  $ value    : num 0.651
##  $ weights  : chr &quot;unweighted&quot;
##  $ StdErr   : num 0.0931
##  $ stat.name: chr &quot;z&quot;
##  $ statistic: num 7
##  $ p.value  : num 2.63e-12
##  $ Po       : num 0.733
##  $ Pe       : num 0.236
##  $ ratings  : chr [1:30, 1:2] &quot;neurosis&quot; &quot;PD&quot; &quot;PD&quot; &quot;other&quot; ...
##   ..- attr(*, &quot;dimnames&quot;)=List of 2
##   .. ..$ : chr [1:30] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;4&quot; ...
##   .. ..$ : chr [1:2] &quot;Psychiatrist1&quot; &quot;Psychiatrist2&quot;
##  - attr(*, &quot;class&quot;)= chr &quot;CohenK&quot;</code></pre>
<p>Confidence intervals of Cohen’s Kappa can be calculated using the jackknife method (Fleiss and Davies, 1982).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ConfintJack</span>(ResultsCohenK)</code></pre></div>
<pre><code>## Statistic       LCL       UCL 
## 0.6511628 0.4492431 0.8530825</code></pre>
</div>
<div id="weighted-kappa" class="section level2">
<h2>3.2 Weighted Kappa</h2>
<p>When the variable is ordinal (and the number of raters equals 2), weighted kappa has to be used (Cohen, 1968). The rationale for weighted kappa is that, in case of ordinal variables, a difference between the ratings 2 and 3 is less severe than a difference between the ratings 1 and 5. Consequently, the pairs of ratings can be given a weight and the value of the weight is dependent on how close the ratings are. If the ratings are identical, a maximal weight of 1 is given and the weights decreases as the ratings diverge from each other.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">data</span>(Agreement_deVet)
<span class="kw">CohenK</span>(Agreement_deVet[,<span class="dv">2</span><span class="op">:</span><span class="dv">3</span>], <span class="dt">weight =</span> <span class="st">&quot;squared&quot;</span>)</code></pre></div>
<pre><code>## 
## #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#
## #       Cohen's Kappa          #
## #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#
## 
## - Number of raters = 2 
## 
## - Sample size = 50 
## 
## - Cohen's Kappa = 0.591 
## 
## - Overall proportion of agreement: 0.935 
## 
## - Proportion chance agreement: 0.8409 
## 
## - Used weights =  squared</code></pre>
<p>As with Cohen’s Kappa, more detailed information can be obtained by storing the output in an object and the confidence intervals can be calculated.</p>
</div>
<div id="fleiss-kappa" class="section level2">
<h2>3.3 Fleiss’ Kappa</h2>
<p>Cohen’s Kappa was later extended to scenarios with multiple raters by Fleiss (1971). To illustrate its use, we can use the dataset from the original article.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">data</span>(PsychMorbid)
<span class="kw">FleissK</span>(PsychMorbid)</code></pre></div>
<pre><code>## 
## #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#
## #  Fleiss' Kappa Coefficient  #
## #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#
## 
## - Number of raters = 6 
## 
## - Sample size = 30 
## 
## - Fleiss' Kappa = 0.43 
## 
## - Overall proportion of agreement: 0.5555556 
## 
## - Proportion chance agreement: 0.2199383</code></pre>
<p>Similar to the function <span class="math inline">\(\verb|CohenK()|\)</span>, detailed information can be obtained by storing the output in an object and the <span class="math inline">\(\verb|ConfintJack()|\)</span> function can be used to get the confidence intervals of Fleiss’ Kappa.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">ResultsFleissK =<span class="st"> </span><span class="kw">FleissK</span>(PsychMorbid)
<span class="kw">str</span>(ResultsFleissK)</code></pre></div>
<pre><code>## List of 16
##  $ method       : chr &quot;Fleiss Kappa&quot;
##  $ subjects     : int 30
##  $ nraters      : int 6
##  $ value        : num 0.43
##  $ StdErr       : num 0.0244
##  $ stat.name    : chr &quot;z&quot;
##  $ statistic    : num 7.94
##  $ lcl          : num 0.319
##  $ ucl          : num 0.541
##  $ p.value      : num 9.37e-09
##  $ alpha        : num 0.05
##  $ Po           : num 0.556
##  $ Pe           : num 0.22
##  $ ratings      :'data.frame':   30 obs. of  6 variables:
##   ..$ Psychiatrist1: Factor w/ 5 levels &quot;PD&quot;,&quot;depression&quot;,..: 3 1 1 4 1 2 5 2 2 4 ...
##   ..$ Psychiatrist2: Factor w/ 5 levels &quot;PD&quot;,&quot;depression&quot;,..: 3 1 5 4 1 2 5 2 2 4 ...
##   ..$ Psychiatrist3: Factor w/ 5 levels &quot;PD&quot;,&quot;depression&quot;,..: 3 1 5 4 1 5 5 5 3 4 ...
##   ..$ Psychiatrist4: Factor w/ 5 levels &quot;PD&quot;,&quot;depression&quot;,..: 3 4 5 4 3 5 5 5 3 4 ...
##   ..$ Psychiatrist5: Factor w/ 5 levels &quot;PD&quot;,&quot;depression&quot;,..: 3 4 5 4 3 5 4 5 3 4 ...
##   ..$ Psychiatrist6: Factor w/ 4 levels &quot;PD&quot;,&quot;neurosis&quot;,..: 2 3 3 3 2 4 3 2 2 3 ...
##  $ weights      : chr &quot;unweighted&quot;
##  $ WeightsMatrix: num [1:5, 1:5] 1 0 0 0 0 0 1 0 0 0 ...
##  - attr(*, &quot;class&quot;)= chr &quot;FleissK&quot;</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ConfintJack</span>(ResultsFleissK)</code></pre></div>
<pre><code>## Statistic       LCL       UCL 
## 0.4302445 0.3223392 0.5381498</code></pre>
</div>
<div id="matrix-of-kappa-type-coefficients" class="section level2">
<h2>3.4 Matrix of Kappa-type coefficients</h2>
<p>If more detailed information on the reliability of a measurement method is desired, we can calculate the Kappa-matrix as described in Roberts and McNamee (1998). Using this matrix, an extensive summary is given of the reliability. The diagonal elements show the kappa coefficients for each of the categories relative to the others and the off-diagonal elements are measures of confusion between categories. The dataset of Fleiss (1971) will be used to illustrate this methodology.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">KMatrix =<span class="st"> </span><span class="kw">Kappa.Matrix</span>(PsychMorbid)
<span class="kw">round</span>(KMatrix<span class="op">$</span>KappaMatrix, <span class="dv">3</span>)</code></pre></div>
<pre><code>##               neurosis     PD  other depression schizophrenia
## neurosis         0.471 -0.183  0.817      0.018         0.935
## PD               0.050  0.245  0.420      0.680         0.400
## other           -0.304 -0.097  0.566      0.420         0.358
## depression      -0.005 -0.115 -0.097      0.245         0.031
## schizophrenia   -0.277 -0.074 -0.090     -0.006         0.520</code></pre>
<p>The results indicate that reliability is highest for the category other (0.566) and lowest for the categories depression and personality disorder (0.245 for both). The upper off-diagonal elements of the matrix are measures of confusion between pairs of categories and are referred to as the interclass kappa coefficient. Values equal to 1 indicate that there is no confusion between categories. For example, <span class="math inline">\(\kappa_{jk}\)</span> with <span class="math inline">\(j\)</span> neurosis and <span class="math inline">\(k\)</span> schizophrenia is equal to 0.935 and thus, the results would indicate that the raters are able to distinguish between patients with diagnoses other and neurosis.</p>
<p>The interpretation of the lower off-diagonal elements is less straightforward. These are the correlation coefficients and the opposite of the interclass kappa coefficients. The correlation coefficient is defined as</p>
<p><span class="math display">\[
\begin{equation}
\begin{aligned}
\lambda_{jk} &amp;= corr[p_{ij}, p_{ik}]\\
&amp;= \frac{\sigma_{jk}}{[P_j (1- P_k) P_k (1 - P_k)]^{1/2}}
\end{aligned}
\end{equation}
\]</span></p>
<p>where <span class="math inline">\(p_{ij}\)</span> is the the proportion of raters who would classify the subject to category <span class="math inline">\(j\)</span> and <span class="math inline">\(P_j\)</span> is the proportion of allocation to category <span class="math inline">\(j\)</span>. See Roberts and McNamee (1998) for detailed information.</p>
<p><span class="math inline">\(\lambda_{jk}\)</span> will be negative when classification to category <span class="math inline">\(j\)</span> excludes classification to category <span class="math inline">\(k\)</span>. Consequently, this indicates that the confusion between the categories is minimal. When there is no confusion at all between the categories, <span class="math inline">\(\lambda_{jk}\)</span> equals</p>
<p><span class="math display">\[
\begin{equation}
\begin{aligned}
\text{min} \ \lambda_{jk} &amp;= - \left[\frac{P_j P_k}{(1 - P_j) (1- P_k)}\right]^{1/2}
\end{aligned}
\end{equation}
\]</span></p>
<p>Conversely, when the categories tend to be confused, <span class="math inline">\(\lambda_{jk}\)</span> approaches 0 or is positive. The maximum value attainable is <span class="math display">\[
\begin{equation}
\begin{aligned}
\text{max} \ \lambda_{jk} &amp;= \left[\frac{P_j (1 - P_k)}{P_k (1 - P_j)}\right]^{1/2}
\end{aligned}
\end{equation}
\]</span></p>
<p>Given that we have to explictly compare the <span class="math inline">\(\lambda_{jk}\)</span> value to its minimum and maximum value possible, this makes it a less attractive and easy-to-interpret statistic. The minimum and maximum possible <span class="math inline">\(\lambda_{jk}\)</span> values are also provided.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Minimum values possible </span>
<span class="kw">round</span>(KMatrix<span class="op">$</span>MinLambda, <span class="dv">3</span>)</code></pre></div>
<pre><code>##               neurosis     PD  other depression schizophrenia
## neurosis            NA     NA     NA         NA            NA
## PD              -0.273     NA     NA         NA            NA
## other           -0.372 -0.230     NA         NA            NA
## depression      -0.273 -0.169 -0.230         NA            NA
## schizophrenia   -0.297 -0.184 -0.251     -0.184            NA</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Maximum values possible</span>
<span class="kw">round</span>(KMatrix<span class="op">$</span>MaxLambda, <span class="dv">3</span>)</code></pre></div>
<pre><code>##               neurosis    PD other depression schizophrenia
## neurosis            NA    NA    NA         NA            NA
## PD               0.619    NA    NA         NA            NA
## other            0.845 1.363    NA         NA            NA
## depression       0.619 1.000 0.733         NA            NA
## schizophrenia    0.674 1.088 0.798      1.088            NA</code></pre>
<p>Note that the latter is not provided when parallel computing is used. This will be implemented in the future.</p>
</div>
<div id="bland-altman-plot-for-multiple-observers" class="section level2">
<h2>3.5 Bland-Altman plot for multiple observers</h2>
<p>If the variable is continuous, reliability can be assessed by use of the intraclass correlation coefficient (ICC, see Shrouten and Fleiss, 1979) and graphically through use of Bland-Altman plots. However, Bland-Altman plots are restricted to scenarios where there are 2 raters and for this reason, Jones et al. (2011) extended the Bland-Altman plot to scenarios with multiple raters.</p>
<p>To illustrate the modified Bland-Altman plot, we will use the same example as used in Jones et al. (2011). In this dataset, 4 dentists gave 10 patients a DMFS score.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">data</span>(DentalStudy)
<span class="kw">par</span>(<span class="dt">cex =</span> <span class="fl">0.5</span>, <span class="dt">cex.lab =</span> <span class="fl">0.75</span>, <span class="dt">cex.axis =</span> <span class="fl">0.7</span>)
ModifBAplot =<span class="st"> </span><span class="kw">BAplotMultipleR</span>(dentist, patient, DMFS, DentalStudy)</code></pre></div>
<p><img src="data:image/png;base64,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" /><!-- --></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">par</span>(<span class="dt">cex =</span> <span class="dv">1</span>, <span class="dt">cex.lab =</span> <span class="dv">1</span>, <span class="dt">cex.axis =</span> <span class="dv">1</span>)</code></pre></div>
<p>In modified Bland-Altman plots, the difference between the average score and the score given by the rater is calculated and plotted. The latter will be referred to as difference scores from here on out. Given that we are working with mean-centered values for each of the subjects, the average of the difference scores is 0 and this depicted in the plot by the dotted line. The limits of agreement (LoA) are given by the solid lines and indicate how different an individual rater can be when compared to the mean measurement of all raters. If, however, the variability of the difference scores increases with the magnitude of the measurement, the default LoA are not appropriate. We then propose to use the option <span class="math inline">\(\verb|LoA=&quot;loess&quot;|\)</span>, which gives the 2.5 and 97.5 percentile curves and this method is based on the method of Royston and Wright (1998).</p>
<p>In addition to the plot, a summary of the two-way ANOVA model is given together with the different ICCs (Shrout and Fleiss, 1979). The results of the ANOVA model indicate whether or not there was a systematic difference between the raters and the ICCs quantify the reliability of the measurement method.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">ModifBAplot</code></pre></div>
<pre><code>## 
## Anova summary:
##             Df Sum Sq Mean Sq F value   Pr(&gt;F)    
## subject      9 2031.7  225.75   81.73  &lt; 2e-16 ***
## rater        3   92.7   30.89   11.18 5.99e-05 ***
## Residuals   27   74.6    2.76                     
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## Call: ICC(x = DfICC)
## 
## Intraclass correlation coefficients 
##                          type  ICC  F df1 df2       p lower bound
## Single_raters_absolute   ICC1 0.91 40   9  30 2.3e-14        0.79
## Single_random_raters     ICC2 0.91 82   9  27 0.0e+00        0.71
## Single_fixed_raters      ICC3 0.95 82   9  27 0.0e+00        0.88
## Average_raters_absolute ICC1k 0.98 40   9  30 2.3e-14        0.94
## Average_random_raters   ICC2k 0.98 82   9  27 0.0e+00        0.91
## Average_fixed_raters    ICC3k 0.99 82   9  27 0.0e+00        0.97
##                         upper bound
## Single_raters_absolute         0.97
## Single_random_raters           0.98
## Single_fixed_raters            0.99
## Average_raters_absolute        0.99
## Average_random_raters          0.99
## Average_fixed_raters           1.00
## 
##  Number of subjects = 10     Number of Judges =  4</code></pre>
</div>
</div>
<div id="data-transformation-of-the-dataframe" class="section level1">
<h1>4. Data transformation of the dataframe</h1>
<p>It may occur that the dataframe has to be transformed in order to be able to use the functions. For this reason, the function <span class="math inline">\(\verb|TransfData()|\)</span> was implemented. We assume that the current dataframe is in the long format and that there are separate variables indicating which subject was rated, which rater made the rating and the value of the rating.</p>
<p>To illustrate this function, we generate some random data.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">Df =<span class="st"> </span><span class="kw">cbind.data.frame</span>(<span class="dt">ID =</span> <span class="kw">sort</span>(<span class="kw">rep</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">10</span>, <span class="dv">4</span>)), <span class="dt">var =</span> <span class="kw">sample</span>(letters[<span class="dv">1</span><span class="op">:</span><span class="dv">2</span>], <span class="dv">40</span>, T), <span class="dt">raters =</span> <span class="kw">rep</span>(<span class="kw">paste</span>(<span class="st">&quot;rater&quot;</span>,<span class="dv">1</span><span class="op">:</span><span class="dv">4</span>), <span class="dv">10</span>))
<span class="kw">head</span>(Df)</code></pre></div>
<pre><code>##   ID var  raters
## 1  1   b rater 1
## 2  1   b rater 2
## 3  1   a rater 3
## 4  1   b rater 4
## 5  2   a rater 1
## 6  2   b rater 2</code></pre>
<p>This dataframe is then given as input in the <span class="math inline">\(\verb|TransfData()|\)</span> function. Once the dataframe is transformed, we can use it as input for the functions of the package.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">NewDf =<span class="st"> </span><span class="kw">TransfData</span>(ID, var, raters, Df)
<span class="kw">FleissK</span>(NewDf)</code></pre></div>
<pre><code>## 
## #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#
## #  Fleiss' Kappa Coefficient  #
## #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#
## 
## - Number of raters = 4 
## 
## - Sample size = 10 
## 
## - Fleiss' Kappa = -0.17 
## 
## - Overall proportion of agreement: 0.4166667 
## 
## - Proportion chance agreement: 0.50125</code></pre>
</div>
<div id="references" class="section level1">
<h1>References</h1>
<p>Cohen, J. (1960). A Coefficient of Agreement for Nominal Scales. <em>Educational and Psychological Measurement</em>, <strong>Vol.20</strong>(1), pp.37-46</p>
<p>Cohen, J. (1968). Weighted kappa: Nominal scale agreement provision for scaled disagreement or partial credit. <em>Psychological Bulletin</em>, <strong>Vol.70</strong>(4), pp.213-220</p>
<p>de Vet, H.C.W., Dikmans, R.E., Eekhout, I. (2017). Specific agreement on dichotomous outcomes can be calculated for more than two raters. <em>Journal of Clinical Epidemiology</em>, <strong>Vol.83</strong>, pp.85-89</p>
<p>de Vet, H.C.W., Mokkink L.B., Terwee C.B., Hoekstra O.S., Knol D.L. (2013). Clinicians are right not to like Cohen’s <span class="math inline">\(\kappa\)</span>. <em>BMJ</em>, <strong>Vol.346</strong></p>
<p>Fleiss, J. L. (1971). Measuring nominal scale agreement among many raters. <em>Psychological Bulletin</em>, <strong>Vol.76</strong>(5), pp.378-382</p>
<p>Fleiss, J.L., Davies, M. (1982). Jackknifing functions of multinomial frequencies, with an application to a measure of concordance. <em>Am J Epidemiol</em>, <strong>Vol.115</strong>, 841-845.</p>
<p>Jones, M., Dobson, A., O’Brian, S. (2011). A graphical method for assessing agreement with the mean between multiple observers using continuous measures. <em>Int J Epidemiol</em>, <strong>Vol.40</strong>, pp. 1308-1313.</p>
<p>Roberts C., McNamee R. (1998). A matrix of kappa-type coefficients to assess the reliability of nominal scales. <em>Statistics in medicine</em>, <strong>Vol.17</strong>(4), pp.471-88</p>
<p>Royston, P., Wright, E.M. (1988). How to construct ‘normal ranges’ for fetal variables. <em>Ultrasound Obstet Gynecol</em>, <strong>Vol.11</strong>: pp. 30-38</p>
<p>Shrout, P.E., Fleiss, J.L. (1979). Intraclass correlations: Uses in assessing rater reliability. <em>Psychol Bull</em>, <strong>Vol.86</strong>, pp. 420-428</p>
<p>Uebersax, J.S. (1982). A design-independent method for measuring the reliability of psychiatric diagnosis. <em>Journal of Psychiatric Research</em>, <strong>Vol.17</strong>(4), pp.335-342</p>
</div>



<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
